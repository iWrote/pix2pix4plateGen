{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "import os \n",
    "import glob\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\", train = True, download = True, transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasets.MNIST(\"\", train = False, download = True, transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper params\n",
    "#I HAVE FLIPPED LABELS\n",
    "bs = 100\n",
    "gIns = 100\n",
    "EPOCHS = 500\n",
    "lrG = 0.0002\n",
    "lrD = 0.0002\n",
    "labelSmoothing = 0.1 # keep in [0,1)\n",
    "noiseAmp = 1  # should i? https://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/\n",
    "loss_fn = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=bs, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=bs, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D(\n",
      "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(D, self).__init__() \n",
    "        self.fc1 = nn.Linear((28*28), 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        x = F.dropout(x, 0.3)\n",
    "        x = self.fc4(x)\n",
    "                         \n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "dsk = D().to(device)\n",
    "#dsk.load_state_dict(torch.load(\".genT.pth\"))\n",
    "print(dsk)\n",
    "optimizerD = optim.Adam(dsk.parameters(), lr=lrD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G(\n",
      "  (fc1): Linear(in_features=100, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=1024, bias=True)\n",
      "  (fc4): Linear(in_features=1024, out_features=784, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class G(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        self.fc1 = nn.Linear(gIns, 256)\n",
    "        self.fc2 = nn.Linear(256, 512)\n",
    "        self.fc3 = nn.Linear(512, 1024)\n",
    "        self.fc4 = nn.Linear(1024, 784)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
    "        #x = F.dropout(x, 0.5)\n",
    "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
    "        #x = F.dropout(x, 0.5)\n",
    "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
    "        #x = F.dropout(x, 0.5)\n",
    "        x = self.fc4(x)\n",
    "                         \n",
    "        return torch.tanh(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "gen = G().to(device)\n",
    "print(gen)\n",
    "optimizerG = optim.Adam(gen.parameters(), lr=lrG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9513c0e51fd44ddabcb5a7ce077b666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-574deebb80d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mdskOnReal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdsk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatchOfData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mlossD_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdskOnReal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabelSmoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mlossD_real\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#clearing image folder\n",
    "files = glob.glob('./mnistGanImgG/*')\n",
    "for file in files:\n",
    "    os.remove(file)\n",
    "\n",
    "\n",
    "with open(\"toyGanMnistTuningLog.log\", \"w\") as f:\n",
    "    \n",
    "    f.write(f\"time, dskOnReal, dskOnFake, epoch\\n\")\n",
    "    \n",
    "    seed = torch.randn(64, 1, gIns).to(device)\n",
    "    \n",
    "    \n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "        #print(epoch)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        #saving batch_size sheet of generated images every epoch\n",
    "        #https://ezgif.com/maker/ezgif-5-d0395d50-gif  CAN make gifs here\n",
    "        with torch.no_grad():\n",
    "            img = gen(seed)\n",
    "            imgpath = f\"./mnistGanImgG/{epoch}.png\"\n",
    "            save_image(img.view(img.size(0), 1, 28, 28), imgpath)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        for _, data in enumerate(trainset):\n",
    "\n",
    "\n",
    "            batchOfData, _ = data \n",
    "            batchOfData = batchOfData.view(-1, 1, 28*28).to(device)\n",
    "########################################################################\n",
    "            dsk.zero_grad()\n",
    "            dskOnReal = dsk(batchOfData)\n",
    "            lossD_real = loss_fn(dskOnReal, torch.zeros(bs,1,1).to(device) + torch.ones(bs,1,1).to(device)*(labelSmoothing))\n",
    "            lossD_real.backward()\n",
    "\n",
    "\n",
    "            batchOfFake = gen(torch.randn(bs, 1, gIns).to(device))\n",
    "            dskOnFake = dsk(batchOfFake.detach())\n",
    "            #https://github.com/pytorch/examples/issues/116\n",
    "            lossD_fake = loss_fn(dskOnFake, torch.ones(bs,1,1).to(device) - torch.ones(bs,1,1).to(device)*(labelSmoothing))\n",
    "            lossD_fake.backward()\n",
    "\n",
    "            #lossD = loss_fn(dskOnReal, torch.ones(100,1,1).to(device))) + loss_fn(dskOnFake, torch.zeros(100,1,1).to(device))\n",
    "\n",
    "            optimizerD.step()\n",
    "################################################################################\n",
    "        \n",
    "            gen.zero_grad()\n",
    "            dskOnFake = dsk(batchOfFake)\n",
    "            lossG = loss_fn(dskOnFake, torch.zeros(bs,1,1).to(device) + torch.ones(bs,1,1).to(device)*(labelSmoothing))\n",
    "            #loss(fake, realLabel)\n",
    "            lossG.backward()\n",
    "            optimizerG.step()\n",
    "\n",
    "            #mean over the batch\n",
    "            \n",
    "            #print(f\"dskOnReal:{dskOnReal.mean().item()}   dskOnFake:{dskOnFake.mean().item()}\")\n",
    "            \n",
    "            #dskOnReal should start close to 1 then theoretically converge to 0.5 when G gets better.\n",
    "            #dskOnFake should start near 0 and converge to 0.5 as G gets better.\n",
    "            f.write(f\"{round(time.time(), 4)}, {round(float(dskOnReal.mean()),3)}, {round(float(dskOnFake.mean()), 4)}, {epoch}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"toyGanMnistTuningLog.log\")\n",
    "df.shape\n",
    "#help(df.loc)\n",
    "\n",
    "#plt.subplot(1,2,1)\n",
    "#df[' dskOnReal'].plot(legend = True)\n",
    "#df[' dskOnFake'].plot(legend = True)\n",
    "#df.plot(x = ' dskOnFake', y = ' dskOnReal', legend = True)\n",
    "\n",
    "\n",
    "df.rolling(window=bs)[' dskOnReal'].mean().plot(legend = True)\n",
    "df.rolling(window=bs)[' dskOnFake'].mean().plot(legend = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "see = gen(torch.randn(1, 1, gIns).to(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 784])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "see.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 100])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(1, 1, gIns).to(device).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gIns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "see = see.view(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "see.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen.state_dict(), \".genT.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dsk.state_dict(), \".dskT.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = G()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD = D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = G()\n",
    "netG.load_state_dict(torch.load(\".genT.pth\"))\n",
    "netG.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESPONSE TO NOISE\n",
    "see = netG(torch.randn(1, 1, gIns))\n",
    "\n",
    "see.shape\n",
    "\n",
    "see = see.view(28, 28)\n",
    "\n",
    "plt.imshow(see.detach().numpy(), cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESPONSE TO ZEROS\n",
    "see = netG(torch.zeros(1, gIns))\n",
    "\n",
    "see.shape\n",
    "\n",
    "see = see.view(28, 28)\n",
    "\n",
    "plt.imshow(see.detach().numpy(), cmap = \"gray\")\n",
    "see.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stadf = \"./mnistGanImgG\\\\\" + str(3) + \".png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    imgpath = glob.glob(f\"./mnistGanImgG\\{i}.png\")\n",
    "    frames.append(imageio.imread(imgpath))\n",
    "\n",
    "imageio.mimwrite('epochs.gif', frames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
