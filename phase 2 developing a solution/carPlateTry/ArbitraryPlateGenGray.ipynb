{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from torchviz import make_dot\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "import os \n",
    "import glob\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import imageio\n",
    "\n",
    "import enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        #reduce to features\n",
    "        self.c0 = nn.Conv2d(in_channels, 64, 4, stride=2, padding=1)\n",
    "        self.c1 = nn.Conv2d(64, 128, 4, stride=2, padding=1)\n",
    "        self.c2 = nn.Conv2d(128, 256, 4, stride=2, padding=1)\n",
    "        self.c3 = nn.Conv2d(256, 512, 4, stride=2, padding=1)\n",
    "        self.c4 = nn.Conv2d(512, 512, 4, stride=2, padding=1)\n",
    "        self.c5 = nn.Conv2d(512, 512, 4, stride=2, padding=1)\n",
    "        self.c6 = nn.Conv2d(512, 512, 4, stride=2, padding=1)\n",
    "        self.c7 = nn.Conv2d(512, 512, 4, stride=2, padding=1)\n",
    "        \n",
    "        #upsample to image\n",
    "        self.d7 = nn.ConvTranspose2d(512, 512, 4, stride=2, padding=1)\n",
    "        self.d6 = nn.ConvTranspose2d(1024, 512, 4, stride=2, padding=1)\n",
    "        self.d5 = nn.ConvTranspose2d(1024, 512, 4, stride=2, padding=1)\n",
    "        self.d4 = nn.ConvTranspose2d(1024, 512, 4, stride=2, padding=1)\n",
    "        self.d3 = nn.ConvTranspose2d(1024, 256, 4, stride=2, padding=1)\n",
    "        self.d2 = nn.ConvTranspose2d(512, 128, 4, stride=2, padding=1)\n",
    "        self.d1 = nn.ConvTranspose2d(256, 64, 4, stride=2, padding=1)\n",
    "        self.d0 = nn.ConvTranspose2d(128, out_channels, 4, stride=2, padding=1)\n",
    "       \n",
    "        self.bnc1 = nn.BatchNorm2d(128)\n",
    "        self.bnc2 = nn.BatchNorm2d(256)\n",
    "        self.bnc3 = nn.BatchNorm2d(512)\n",
    "        self.bnc4 = nn.BatchNorm2d(512)\n",
    "        self.bnc5 = nn.BatchNorm2d(512)\n",
    "        self.bnc6 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.bnd7 = nn.BatchNorm2d(512)\n",
    "        self.bnd6 = nn.BatchNorm2d(512)\n",
    "        self.bnd5 = nn.BatchNorm2d(512)\n",
    "        self.bnd4 = nn.BatchNorm2d(512)\n",
    "        self.bnd3 = nn.BatchNorm2d(256)\n",
    "        self.bnd2 = nn.BatchNorm2d(128)\n",
    "        self.bnd1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "    def forward(self, x):           \n",
    "        en0 = self.c0(x)\n",
    "        en1 = self.bnc1(self.c1(F.leaky_relu(en0, negative_slope=0.2)))\n",
    "        en2 = self.bnc2(self.c2(F.leaky_relu(en1, negative_slope=0.2)))\n",
    "        en3 = self.bnc3(self.c3(F.leaky_relu(en2, negative_slope=0.2)))\n",
    "        en4 = self.bnc4(self.c4(F.leaky_relu(en3, negative_slope=0.2)))\n",
    "        en5 = self.bnc5(self.c5(F.leaky_relu(en4, negative_slope=0.2)))\n",
    "        en6 = self.bnc6(self.c6(F.leaky_relu(en5, negative_slope=0.2)))\n",
    "        en7 = self.c7(F.leaky_relu(en6, negative_slope=0.2))\n",
    "\n",
    "        de7 = self.bnd7(self.d7(F.relu(en7)))\n",
    "        de6 = F.dropout(self.bnd6(self.d6(F.relu(torch.cat((en6, de7),1)))))\n",
    "        de5 = F.dropout(self.bnd5(self.d5(F.relu(torch.cat((en5, de6),1)))))\n",
    "\n",
    "        de4 = F.dropout(self.bnd4(self.d4(F.relu(torch.cat((en4, de5),1)))))\n",
    "        de3 = self.bnd3(self.d3(F.relu(torch.cat((en3, de4),1))))\n",
    "        de2 = self.bnd2(self.d2(F.relu(torch.cat((en2, de3),1))))\n",
    "        de1 = self.bnd1(self.d1(F.relu(torch.cat((en1, de2),1))))\n",
    "\n",
    "        de0 = torch.tanh(self.d0(F.relu(torch.cat((en0, de1),1))))       \n",
    "\n",
    "        return de0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Zero images were written.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-5e55950e275a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"epochs.gif\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mmimwrite\u001b[1;34m(uri, ims, format, **kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[1;31m# be a generator. The damage is done, but we want to error when it happens.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mwritten\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Zero images were written.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[1;31m# Return a result if there is any\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Zero images were written."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "images = []\n",
    "j = 0\n",
    "for i in glob.glob(\"./generated_images/*\"):    \n",
    "    img = imageio.imread(i)\n",
    "    #cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "    img = cv2.putText(img, str(j), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2, cv2.LINE_AA)\n",
    "    images.append(img)\n",
    "    j+=1\n",
    "    \n",
    "\n",
    "imageio.mimwrite(\"epochs.gif\", images, fps = 50, loop = 0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 256, 512])\n"
     ]
    }
   ],
   "source": [
    "netG = Generator(1,1).to(device)\n",
    "netG.load_state_dict(torch.load('./epochModelParamData/G105.pth'))\n",
    "netG.eval()\n",
    "\n",
    "pug = cv2.imread('./ThePugTest.png', cv2.IMREAD_GRAYSCALE)\n",
    "#pug = y\n",
    "pug = pug.astype(np.float32)\n",
    "pug = pug/127.5 - 1 \n",
    "pug = torch.tensor(pug).to(device)\n",
    "pug = pug.unsqueeze(0).unsqueeze(0)\n",
    "print(pug.shape)\n",
    "\n",
    "pug_plate_of_truth = netG(pug)\n",
    "\n",
    "pug_plate_of_truth = pug_plate_of_truth.squeeze(0).squeeze(0)\n",
    "pug = pug.squeeze(0).squeeze(0)\n",
    "pug_plate = torch.cat((pug,pug_plate_of_truth),1)\n",
    "pug_plate = pug_plate.cpu().detach().numpy()\n",
    "\n",
    "pug_plate = (pug_plate + 1)/2 *255\n",
    "pug_plate = pug_plate.astype(np.uint8)\n",
    "%matplotlib qt\n",
    "plt.imshow(pug_plate, cmap=\"gray\")\n",
    "imageio.imwrite('pug_plate.png', pug_plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "y  = np.zeros((256, 512)).astype(np.uint8) + 255\n",
    "start = (106,156//2) \n",
    "end = (406, 156//2 + 100)\n",
    "start2 = (106+3,156//2+3) \n",
    "end2 = (406-3, 156//2 + 100 -3)\n",
    "y = cv2.rectangle(y, start, end, (0,0,0), -1)\n",
    "y = cv2.rectangle(y, start2, end2, (255,255,255), 2)\n",
    "y = cv2.putText(y, \"UP 32 FV 7298\", (132, 139), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "#y = cv2.blur(y, (5,5))\n",
    "\n",
    "pmatrix = np.array(([0.8647, 0.01, 19.4354], [0.1762, 0.8919, 25.2840], [0,0,1]))\n",
    "\n",
    "#pmatrix = np.array(([1,0,0], [0,1,0], [0,0,1])).astype(np.float32)\n",
    "\n",
    "y = cv2.warpPerspective(y, pmatrix, dsize = (512, 256), borderValue = np.ones(3)*255)\n",
    "\n",
    "\n",
    "plt.imshow(y, cmap = \"gray\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "imageio.imwrite('./y.png', y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83398015, 0.57532914, 0.16970007])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
