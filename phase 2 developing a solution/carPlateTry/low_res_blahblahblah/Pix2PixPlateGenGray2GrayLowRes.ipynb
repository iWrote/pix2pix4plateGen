{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torchvision.utils import save_image, make_grid\n",
    "\n",
    "from torchviz import make_dot\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "import os \n",
    "import glob\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import imageio\n",
    "\n",
    "import enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparams & options\n",
    "\n",
    "EPOCHS = 10\n",
    "lrD = 0.0002\n",
    "lrG = 0.0002\n",
    "bs = 1  #https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/issues/27#issuecomment-346495489\n",
    "loss_fn = nn.BCELoss().to(device)\n",
    "loss_fn_img = nn.L1Loss().to(device)\n",
    "LAMBDA = 100\n",
    "\n",
    "labelSmoothingFactor = 0.08\n",
    "flip_labels = True\n",
    "training_set_size = 865 - 15\n",
    "\n",
    "CheckpointPeriod = 1 #save the model every <CheckpointPeriod> epochs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dsk(nn.Module):\n",
    "    \n",
    "    def __init__(self, d=64):\n",
    "        super(Dsk, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(2, d, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(d, d * 2, 4, 2, 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(d * 2)\n",
    "        self.conv3 = nn.Conv2d(d * 2, d * 4, 4, 2, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(d * 4)\n",
    "        self.conv4 = nn.Conv2d(d * 4, d * 8, 4, 1, 1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(d * 8)\n",
    "        self.conv5 = nn.Conv2d(d * 8, 1, 4, 1, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), 0.2)\n",
    "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
    "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "           \n",
    "        #reduce to features\n",
    "        self.c0 = nn.Conv2d(in_channels, 64, 4, stride=2, padding=1)\n",
    "        self.c1 = nn.Conv2d(64, 128, 4, stride=2, padding=1)\n",
    "        self.c2 = nn.Conv2d(128, 256, 4, stride=2, padding=1)\n",
    "        self.c3 = nn.Conv2d(256, 512, 4, stride=2, padding=1)\n",
    "      \n",
    "        \n",
    "        #upsample to image\n",
    "        \n",
    "        self.d3 = nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1)\n",
    "        self.d2 = nn.ConvTranspose2d(512, 128, 4, stride=2, padding=1)\n",
    "        self.d1 = nn.ConvTranspose2d(256, 64, 4, stride=2, padding=1)\n",
    "        self.d0 = nn.ConvTranspose2d(128, out_channels, 4, stride=2, padding=1)\n",
    "       \n",
    "        self.bnc1 = nn.BatchNorm2d(128)\n",
    "        self.bnc2 = nn.BatchNorm2d(256)\n",
    "        self.bnc3 = nn.BatchNorm2d(512)\n",
    "        \n",
    "\n",
    "      \n",
    "        self.bnd3 = nn.BatchNorm2d(256)\n",
    "        self.bnd2 = nn.BatchNorm2d(128)\n",
    "        self.bnd1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):           \n",
    "                \n",
    "        en0 = self.c0(x)\n",
    "        en1 = self.bnc1(self.c1(F.leaky_relu(en0, negative_slope=0.2)))\n",
    "        en2 = self.bnc2(self.c2(F.leaky_relu(en1, negative_slope=0.2)))\n",
    "        en3 = self.bnc3(self.c3(F.leaky_relu(en2, negative_slope=0.2)))\n",
    "        \n",
    "        de3 = self.bnd3(self.d3(F.relu(en3)))\n",
    "        de2 = F.dropout(self.bnd2(self.d2(F.relu(torch.cat((en2, de3),1)))))\n",
    "        de1 = self.bnd1(self.d1(F.relu(torch.cat((en1, de2),1))))\n",
    "\n",
    "        de0 = torch.tanh(self.d0(F.relu(torch.cat((en0, de1),1))))\n",
    "\n",
    "        return de0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Dsk().to(device)\n",
    "optimizerD = optim.Adam(D.parameters(), lr=lrD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(1,1).to(device)\n",
    "optimizerG = optim.Adam(G.parameters(), lr=lrG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(D(torch.ones(1,2,32,128).cuda().detach())).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nG.load_state_dict(torch.load('G15.pth'))\\nD.load_state_dict(torch.load('D15.pth'))\\nG.eval()\\nD.eval()\\n\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOAD STATE DICTs IF CONTINUING TRAINING\n",
    "\n",
    "'''\n",
    "\n",
    "G.load_state_dict(torch.load('G15.pth'))\n",
    "D.load_state_dict(torch.load('D15.pth'))\n",
    "G.eval()\n",
    "D.eval()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "865\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(np.load('cdac_data.npy')).float().to(device)\n",
    "print(len(data))\n",
    "#data is (N, outchannels + inchannels, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([850, 1, 32, 128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData = data[:training_set_size]\n",
    "testData = data[training_set_size:]\n",
    "testData.shape\n",
    "trainData[:,0,:,:].unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mkdir failed. ./generated_images/. Reason: [WinError 183] Cannot create a file when that file already exists: './generated_images/'\n",
      "Mkdir failed. ./epochModelParamData/. Reason: [WinError 183] Cannot create a file when that file already exists: './epochModelParamData/'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a770c5c75acd44238deb425f22ccc308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f31a8cf833d46d1b31424e401d342f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=850), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb79287ec22468d905f897055b0aa56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=850), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daaf1e3d95a74f5e97e979ecc0f921cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=850), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b9c41cb6a74e5fae89de94c2376dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=850), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab3e275265d46c38a2687a254703d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=850), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcac1739bc89469fa4d8e8739e977e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=850), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7643ad906b442cb73677ec24e72235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=850), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15828d2ec06141c9b8e526f63895e4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=850), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f4d9e4a14643b68dc620c35dee3869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=850), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36793a992aa4423189e151507949955d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=850), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if(flip_labels):    \n",
    "    zeroLabel = torch.zeros(bs*28).to(device) + labelSmoothingFactor\n",
    "    oneLabel = torch.ones(bs*28).to(device) - labelSmoothingFactor\n",
    "else:\n",
    "    zeroLabel = torch.ones(bs*28).to(device) - labelSmoothingFactor\n",
    "    oneLabel = torch.zeros(bs*28).to(device) + labelSmoothingFactor\n",
    "\n",
    "\n",
    "with open(\"pix2pixPlateGenLog.log\", \"w\") as logfile:\n",
    "    \n",
    "    #creating image folder\n",
    "    try:\n",
    "        os.mkdir('./generated_images/')\n",
    "    \n",
    "    except Exception as e:\n",
    "        print('Mkdir failed. %s. Reason: %s' % ('./generated_images/', e))\n",
    "    \n",
    "    \n",
    "    #clearing image folder\n",
    "    files = glob.glob('./generated_images/*')\n",
    "    for file in files:\n",
    "        os.remove(file)\n",
    "        \n",
    "    #creating models folder\n",
    "    try:\n",
    "        os.mkdir('./epochModelParamData/')\n",
    "    \n",
    "    except Exception as e:\n",
    "        print('Mkdir failed. %s. Reason: %s' % ('./epochModelParamData/', e))\n",
    "    \n",
    "    #clearing models folder\n",
    "    files = glob.glob('./epochModelParamData/*')\n",
    "    for file in files:\n",
    "        os.remove(file)\n",
    "        \n",
    "    \n",
    "\n",
    "    #logfile csv header\n",
    "    logfile.write(f\"time,D_loss_real,D_loss_fake,G_loss,epoch\\n\")\n",
    "    \n",
    "    for epoch in tqdm(range(EPOCHS)):\n",
    "             \n",
    "        for i in tqdm(range(0, training_set_size, bs)):\n",
    "\n",
    "            batchOfRealPairs = trainData[i:i+bs]           #(bs, 2, 32, 128)\n",
    "            batchOfRealImgs = batchOfRealPairs[:,0,:,:].unsqueeze(1)   #(bs, 1, 32, 128)\n",
    "            batchOfOutlines = batchOfRealPairs[:,1,:,:].unsqueeze(1)   #(bs, 1, 32, 128)\n",
    "\n",
    "\n",
    "            D.zero_grad()\n",
    "            \n",
    "            D_real = torch.flatten(D(batchOfRealPairs))\n",
    "            D_loss_real = loss_fn(D_real, oneLabel)\n",
    "            D_loss_real.backward()\n",
    "\n",
    "            batchOfFakeImgs = G(batchOfOutlines)    #(bs, 1, 32, 128)\n",
    "            batchOfFakePairs = torch.cat((batchOfFakeImgs, batchOfOutlines), 1)  #(bs, 2, 32, 128)\n",
    "            D_fake = torch.flatten(D(batchOfFakePairs.detach()))  #https://github.com/pytorch/examples/issues/116\n",
    "            D_loss_fake = loss_fn(D_fake, zeroLabel) #bce(bs,28 & bs, 28)\n",
    "            D_loss_fake.backward()\n",
    "\n",
    "            optimizerD.step()\n",
    "\n",
    "\n",
    "            G.zero_grad()\n",
    "\n",
    "            D_fake = torch.flatten(D(batchOfFakePairs)) \n",
    "            G_loss = loss_fn(D_fake, oneLabel) + LAMBDA*loss_fn_img(batchOfFakeImgs, batchOfRealImgs)\n",
    "            G_loss.backward()\n",
    "\n",
    "            optimizerG.step()\n",
    "            \n",
    "            \n",
    "            #logging in a file and printing\n",
    "            logfile.write(f\"{round(time.time(), 4)},{round(D_loss_real.mean().item(), 3)},{round(D_loss_fake.mean().item(), 3)},{round(G_loss.mean().item(), 3)},{epoch}\\n\")\n",
    "            #print(f\"{round(time.time(), 4):15} | {round(D_loss_real.mean().item(), 3):5} | {round(D_loss_fake.mean().item(), 3):5} | {round(G_loss.mean().item(), 3):7} | {epoch:03} | {i}\\n\")\n",
    "            \n",
    "        \n",
    "        #save imagees generated from testset and save model state every epoch\n",
    "        epochImagePath = f\"./generated_images/{epoch}.png\"\n",
    "        with torch.no_grad():\n",
    "            generated_images = G(testData[:,1,:,:].unsqueeze(1))\n",
    "            image_pairs = torch.cat((testData[:,1,:,:].unsqueeze(1), generated_images), 3)\n",
    "            image_pairs = make_grid(image_pairs, nrow = 5)\n",
    "            u = image_pairs.cpu().numpy().astype(np.float32)\n",
    "            u = np.rint(((u + 1)/2)*255).astype(np.uint8)\n",
    "            u = u.transpose(1,2,0)\n",
    "            imageio.imwrite(epochImagePath, u)\n",
    "            if(epoch%CheckpointPeriod == 0): #state dictionarys are crazy large\n",
    "                torch.save(D.state_dict(), f\"./epochModelParamData/D{epoch}.pth\")\n",
    "                torch.save(G.state_dict(), f\"./epochModelParamData/G{epoch}.pth\")\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a GIF\n",
    "\n",
    "images = []\n",
    "j = 0\n",
    "for i in glob.glob(\"./generated_images/*\"):    \n",
    "    img = imageio.imread(i)\n",
    "    #cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "    img = cv2.putText(img, str(j), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2, cv2.LINE_AA)\n",
    "    images.append(img)\n",
    "    j+=1\n",
    "    \n",
    "\n",
    "imageio.mimwrite(\"epochs.gif\", images, fps = 60, loop = 0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 32, 128])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "netG = Generator(1,1).to(device)\n",
    "netG.load_state_dict(torch.load('./epochModelParamData\\G3.pth'))\n",
    "\n",
    "pug = cv2.imread('./ThePugTest.png', cv2.IMREAD_GRAYSCALE)\n",
    "pug = pug.astype(np.float32)\n",
    "pug = pug/127.5 - 1 \n",
    "pug = torch.tensor(pug).to(device)\n",
    "pug = pug.unsqueeze(0).unsqueeze(0)\n",
    "print(pug.shape)\n",
    "\n",
    "pug_plate_of_truth = netG(pug)\n",
    "\n",
    "pug_plate_of_truth = pug_plate_of_truth.squeeze(0).squeeze(0)\n",
    "pug = pug.squeeze(0).squeeze(0)\n",
    "pug_plate = torch.cat((pug,pug_plate_of_truth),1)\n",
    "pug_plate = pug_plate.cpu().detach().numpy()\n",
    "\n",
    "pug_plate = (pug_plate + 1)/2 *255\n",
    "pug_plate = pug_plate.astype(np.uint8)\n",
    "\n",
    "\n",
    "pug_plate = cv2.blur(pug_plate, (2,2))\n",
    "plt.imshow(pug_plate, cmap=\"gray\")\n",
    "\n",
    "imageio.imwrite('pug_plate.png', pug_plate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d852246108>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df = pd.read_csv('pix2pixPlateGenLog.log')\n",
    "df.rolling(window = 800)['G_loss'].mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function imwrite in module imageio.core.functions:\n",
      "\n",
      "imwrite(uri, im, format=None, **kwargs)\n",
      "    imwrite(uri, im, format=None, **kwargs)\n",
      "    \n",
      "    Write an image to the specified file.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    uri : {str, pathlib.Path, file}\n",
      "        The resource to write the image to, e.g. a filename, pathlib.Path\n",
      "        or file object, see the docs for more info.\n",
      "    im : numpy.ndarray\n",
      "        The image data. Must be NxM, NxMx3 or NxMx4.\n",
      "    format : str\n",
      "        The format to use to read the file. By default imageio selects\n",
      "        the appropriate for you based on the filename and its contents.\n",
      "    kwargs : ...\n",
      "        Further keyword arguments are passed to the writer. See :func:`.help`\n",
      "        to see what arguments are available for a particular format.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(imageio.imwrite)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
